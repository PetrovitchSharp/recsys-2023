{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "046c1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d552be",
   "metadata": {},
   "source": [
    "## Преобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12581d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 1160084/1160084 [00:40<00:00, 28681.62it/s]\n"
     ]
    }
   ],
   "source": [
    "likes_tables = []\n",
    "\n",
    "with open('train', 'r') as train_file:\n",
    "    for i, tracks_line in enumerate(tqdm(train_file.readlines())):\n",
    "        # Split each line to get list of tracks ids\n",
    "        tracks_ids = [int(n) for n in tracks_line.split()]\n",
    "        # Reverse tracks ids list to make last like the most relevant one\n",
    "        # And make it a numpy array\n",
    "        tracks_ids = np.array(tracks_ids[::-1])\n",
    "        # And reshape it to create a column with tracks ids\n",
    "        tracks_ids_column = tracks_ids.reshape(-1,1)\n",
    "\n",
    "        # Create a column with user pseudo id\n",
    "        user_id_column = np.full_like(tracks_ids_column, i)\n",
    "        \n",
    "        # Horizontal stack columns to create a part of future dataset\n",
    "        user_likes = np.hstack((user_id_column, tracks_ids_column))\n",
    "        # And push it to the list\n",
    "        likes_tables.append(user_likes)\n",
    "        \n",
    "# Vectical stack list values to create united matrix with 2 columns\n",
    "# And then create a dataset from it\n",
    "df = pd.DataFrame(np.vstack(likes_tables), columns = ['user_id', 'track_id'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3981ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define order column\n",
    "df['order'] = df.groupby('user_id').cumcount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035cc6c",
   "metadata": {},
   "source": [
    "## UserKFoldLeavePOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04a77dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UsersKFoldPOut():\n",
    "    def __init__(self, n_folds: int, p: int, random_seed: int = 23):\n",
    "        self.n_folds = n_folds\n",
    "        self.p = p\n",
    "        self.random_seed = random_seed\n",
    "    \n",
    "    def split(self, df: pd.DataFrame):\n",
    "        # Set random seed\n",
    "        np.random.seed(self.random_seed)\n",
    "        \n",
    "        # Get unique users list and its length\n",
    "        users = df['user_id'].unique()\n",
    "        users_count = len(users)\n",
    "        # Shuffle users list\n",
    "        np.random.shuffle(users)\n",
    "        \n",
    "        # Calculate fold sizes\n",
    "        fold_sizes = np.full(self.n_folds, users_count // self.n_folds, dtype=int)\n",
    "        fold_sizes[: users_count % self.n_folds] += 1\n",
    "        \n",
    "        current = 0\n",
    "        for fold_size in fold_sizes:\n",
    "            # Get borders of test fold\n",
    "            start, stop = current, current + fold_size\n",
    "            # Get users list for test fold\n",
    "            test_fold_users = users[start:stop]\n",
    "            \n",
    "            # Create test mask without taking into account the number of interactions\n",
    "            test_mask = df['user_id'].isin(test_fold_users) \n",
    "            # Create train mask as opposite to test mask\n",
    "            train_mask = ~test_mask\n",
    "            # Modify test mask to leave only first p interactions in test\n",
    "            test_mask &= df['order'] < self.p\n",
    "            \n",
    "            current = stop\n",
    "            \n",
    "            yield train_mask, test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6df7e",
   "metadata": {},
   "source": [
    "## Доп функции для проверки правильности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc519d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersections(train: pd.DataFrame, test: pd.DataFrame):\n",
    "    '''Checking for intersections by user_id for the train and test'''\n",
    "    train_users = set(train['user_id'].unique())\n",
    "    test_users = set(test['user_id'].unique())\n",
    "    \n",
    "    intersection = train_users.intersection(test_users)\n",
    "    \n",
    "    return len(intersection) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eae1f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pout(test: pd.DataFrame, p: int):\n",
    "    '''Checking for the presence of no more than k likes in the test'''\n",
    "    return (test.groupby('user_id').track_id.count() <= p).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f220563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def check_unique_folds(test_users: np.ndarray):\n",
    "    '''Checking for the uniqueness of folds'''\n",
    "    intersection = reduce(np.intersect1d, (test_users))\n",
    "    \n",
    "    return len(intersection) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a02c3d",
   "metadata": {},
   "source": [
    "## Проверка правильности разбиения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23e6b3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold#0 | Train size: 62769950, Test size: 1160085\n",
      "Users in train and test are different: True\n",
      "There are no more than 3 likes for each user: True\n",
      "Fold#1 | Train size: 62749697, Test size: 1160085\n",
      "Users in train and test are different: True\n",
      "There are no more than 3 likes for each user: True\n",
      "Fold#2 | Train size: 62857621, Test size: 1160082\n",
      "Users in train and test are different: True\n",
      "There are no more than 3 likes for each user: True\n",
      "All folds are unique: True\n"
     ]
    }
   ],
   "source": [
    "n_folds = 3\n",
    "p = 3\n",
    "\n",
    "cv = UsersKFoldPOut(n_folds = n_folds, p = p)\n",
    "\n",
    "test_users = []\n",
    "\n",
    "for i, (train_mask, test_mask) in enumerate(cv.split(df)):\n",
    "    train = df[train_mask]\n",
    "    test = df[test_mask]\n",
    "    \n",
    "    print(f'Fold#{i} | Train size: {train.shape[0]}, Test size: {test.shape[0]}')\n",
    "    print(f'Users in train and test are different: {check_intersections(train, test)}')\n",
    "    print(f'There are no more than {p} likes for each user: {check_pout(test, p)}')\n",
    "    \n",
    "    test_users.append(test.user_id.unique())\n",
    "    \n",
    "print(f'All folds are unique: {check_unique_folds(test_users)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a672cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
